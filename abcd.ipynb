{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3339ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model as Keras_Model\n",
    "from copy import deepcopy\n",
    "from joblib import load, dump\n",
    "from .get_model import get_model\n",
    "from ..loggers import Logger\n",
    "from ..config import CONFIG, OPTIMIZERS, LR_SCHEDULERS, get_custom_layers, get_model_path, def_callbacks\n",
    "\n",
    "class Model(Keras_Model) :\n",
    "    def __init__(self, name : str = \"custom_model\", **kwargs) :\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.base_model = None\n",
    "        self.model : Keras_Model = None\n",
    "        self.outputs_layer : tf.Tensor = None\n",
    "        self.config : dict = deepcopy(CONFIG)\n",
    "        self.logger : Logger = Logger()\n",
    "        self.callbacks : list = def_callbacks(self.logger)\n",
    "        self.logger.info(\"CNN model initialized\")\n",
    "\n",
    "    @staticmethod\n",
    "    def update_global_config(updates: dict) -> None :\n",
    "        \"\"\"\n",
    "        Updates the global CONFIG dictionary.\n",
    "        This affects all future Model instances created without custom overrides.\n",
    "        \"\"\"\n",
    "        CONFIG.update(updates)\n",
    "        print(\"Global config updated.\")\n",
    "\n",
    "\n",
    "    # ---------------- Model Handling ----------------\n",
    "    def get_base_model(self, name : str) -> 'Model' :\n",
    "        \"\"\"\n",
    "        Used to get the base keras model, example resnet50\n",
    "        Just give the name\n",
    "        regex used to filter the name : '[^a-zA-Z0-9]'\n",
    "        \"\"\"\n",
    "        try :\n",
    "            self.base_model = get_model(self.logger, name)(\n",
    "                weights=\"imagenet\", include_top=False, input_shape=self.config[\"img_size\"] + (3,)\n",
    "            )\n",
    "            self.outputs_layer = self.base_model.output\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(f\"Base model {name} loaded\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(f\"Error loading base model {name} : {e}\")\n",
    "        return self\n",
    "\n",
    "    def rebuild_model(self) -> 'Model' :\n",
    "        if self.base_model is None or self.outputs_layer is None :\n",
    "            self.logger.error(f\"Cannot rebuild model : {\"base_model\" if self.base_model is None else \"outputs_layer\"} missing\")\n",
    "            return\n",
    "        try :\n",
    "            self.model = Keras_Model(inputs=self.base_model.input, outputs=self.outputs_layer)\n",
    "            self.logger.info(\"Model rebuilt successfully\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(f\"Error rebuilding model : {e}\")\n",
    "        return self\n",
    "\n",
    "    def compile(self) -> None :\n",
    "        \"\"\"\n",
    "        Compiles the model using the optimizer and learning rate (or scheduler)\n",
    "        specified in the instance's configuration (if not provided).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            learning_rate_or_schedule = self.config[\"learning_rate\"]\n",
    "            scheduler_name = self.config.get(\"lr_scheduler\")\n",
    "\n",
    "            if scheduler_name and scheduler_name in LR_SCHEDULERS:\n",
    "                scheduler_info = deepcopy(LR_SCHEDULERS[scheduler_name])\n",
    "                scheduler_class = scheduler_info[\"class\"]\n",
    "                scheduler_params = scheduler_info[\"params\"]\n",
    "                \n",
    "                # Override default scheduler params with user-defined ones\n",
    "                scheduler_params.update(self.config.get(\"lr_scheduler_params\", {}))\n",
    "\n",
    "                # Some schedulers require the initial learning rate\n",
    "                if \"initial_learning_rate\" in scheduler_params or scheduler_name == \"piecewise_constant_decay\":\n",
    "                    # For PiecewiseConstantDecay, values can be relative to the learning rate\n",
    "                    if scheduler_name != \"piecewise_constant_decay\":\n",
    "                        scheduler_params[\"initial_learning_rate\"] = self.config[\"learning_rate\"]\n",
    "\n",
    "                learning_rate_or_schedule = scheduler_class(**scheduler_params)\n",
    "                self.logger.info(f\"Using LR Scheduler: {scheduler_name}\")\n",
    "            else:\n",
    "                self.logger.info(f\"Using constant learning rate: {learning_rate_or_schedule}\")\n",
    "\n",
    "            # 2. Instantiate the Optimizer\n",
    "            optimizer_name = self.config[\"optimizer\"]\n",
    "            if optimizer_name not in OPTIMIZERS:\n",
    "                raise ValueError(f\"Optimizer '{optimizer_name}' not found in configuration.\")\n",
    "\n",
    "            optimizer_info = deepcopy(OPTIMIZERS[optimizer_name])\n",
    "            optimizer_class = optimizer_info[\"class\"]\n",
    "            optimizer_params = optimizer_info[\"params\"]\n",
    "\n",
    "            # Add learning rate and any user overrides\n",
    "            optimizer_params[\"learning_rate\"] = learning_rate_or_schedule\n",
    "            optimizer_params.update(self.config.get(\"optimizer_params\", {}))\n",
    "\n",
    "            optimizer_instance = optimizer_class(**optimizer_params)\n",
    "            \n",
    "            # 3. Compile the Keras Model\n",
    "            if not self.model:\n",
    "                self.logger.error(\"Cannot compile: self.model is not built yet.\")\n",
    "                return\n",
    "\n",
    "            self.model.compile(\n",
    "                optimizer=optimizer_instance,\n",
    "                loss=self.config[\"loss\"],\n",
    "                metrics=self.config[\"metrics\"]\n",
    "            )\n",
    "            self.logger.info(f\"Model compiled with Optimizer: {optimizer_name}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(f\"Error compiling model : {e}\")\n",
    "        return self\n",
    "\n",
    "    def summary(self) -> None :\n",
    "        if self.model :\n",
    "            self.model.summary()\n",
    "            self.logger.info(\"Model summary printed\")\n",
    "        else :\n",
    "            self.logger.error(\"No model to summarize\")\n",
    "\n",
    "    def call(self, inputs, training=False) :\n",
    "        return self.model(inputs, training=training)\n",
    "\n",
    "    # ---------------- Saving & Fitting ----------------\n",
    "    def save(self, file_names : tuple[str] = None) :\n",
    "        \"\"\"\n",
    "        file_names : (keras_model.keras, this_model.pkl)\n",
    "        If you do not provide file name, it makes default one from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if file_names is None :\n",
    "                file_names = get_model_path(self.base_model.name)\n",
    "            \n",
    "            self.logger.info(f\"Models saved as {file_names}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(f\"Error saving model : {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load(file_name : str = None) -> 'Model' :\n",
    "        \"\"\"\n",
    "        file_names : this_model.pkl\n",
    "        \"\"\"\n",
    "        try :\n",
    "            model = load(file_name)\n",
    "            print(f\"Model loaded from {file_name}\")\n",
    "            return model\n",
    "        except Exception as e :\n",
    "            print(f\"Error loading model : {e}\")\n",
    "\n",
    "    def fit(self, train, val, epochs : int = None, batch_size : int = None, callbacks : list = None) :\n",
    "        \"\"\"\n",
    "        If you do not provide parameters, it takes default ones from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if callbacks is None :\n",
    "                callbacks = self.callbacks\n",
    "            if epochs is None :\n",
    "                epochs = self.config[\"epochs\"]\n",
    "            if batch_size is None :\n",
    "                batch_size = self.config[\"batch_size\"]\n",
    "\n",
    "            self.logger.info(f\"Training started for {epochs} epochs\")\n",
    "            return super().fit(\n",
    "                train,\n",
    "                validation_data=val,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "        except Exception as e :\n",
    "            self.logger.error(f\"Error during training : {e}\")\n",
    "    \n",
    "\n",
    "    def predict(self, data, batch_size : int = None) :\n",
    "        \"\"\"\n",
    "        If you do not provide batch size, it takes default from config\n",
    "        \"\"\"\n",
    "        if batch_size is None :\n",
    "            batch_size = self.config[\"batch_size\"]\n",
    "        return super().predict(data, batch_size=batch_size)\n",
    "    \n",
    "\n",
    "    def evaluate(self, data, batch_size : int = None) :\n",
    "        \"\"\"\n",
    "        If you do not provide batch size, it takes default from config\n",
    "        \"\"\"\n",
    "        if batch_size is None :\n",
    "            batch_size = self.config[\"batch_size\"]\n",
    "        return super().evaluate(data, batch_size=batch_size)\n",
    "\n",
    "    # ----------------- Freeze / Unfreeze ----------------- #\n",
    "    def freeze_all(self) -> 'Model' :\n",
    "        try :\n",
    "            for i, layer in enumerate(self.model.layers) :\n",
    "                try :\n",
    "                    layer.trainable = False\n",
    "                except Exception as e :\n",
    "                    self.logger.error(f\"Error while freezing layer {i + 1} ({layer.name}) : {e}\")\n",
    "            self.logger.info(\"All layers frozen\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def freeze_early_N(self, N : int = None) -> 'Model' :\n",
    "        \"\"\"\n",
    "        If you do not provide N, it takes default from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if N is None :\n",
    "                N = self.config[\"N\"]\n",
    "            for i, layer in enumerate(self.model.layers[N :]) :\n",
    "                try :\n",
    "                    layer.trainable = False\n",
    "                except Exception as e :\n",
    "                    self.logger.error(f\"Error while freezing layer {i + 1} ({layer.name}) : {e}\")\n",
    "            self.logger.info(f\"Froze all layers after first {N}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def freeze_upto_layer(self, layer_name : str = None) -> 'Model' :\n",
    "        try :\n",
    "            for i, layer in enumerate(self.model.layers) :\n",
    "                try :\n",
    "                    layer.trainable = False\n",
    "                    if layer.name == layer_name :\n",
    "                        break\n",
    "                except Exception as e :\n",
    "                    self.logger.error(f\"Error while freezing layer {i + 1} ({layer.name}) : {e}\")\n",
    "            self.logger.info(f\"Froze layers up to {layer_name}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def unfreeze_later_N(self, N : int = None) -> 'Model' :\n",
    "        \"\"\"\n",
    "        If you do not provide N, it takes default from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if N is None :\n",
    "                N = self.config[\"N\"]\n",
    "            for i, layer in enumerate(self.model.layers[-N :]) :\n",
    "                try :\n",
    "                    layer.trainable = True\n",
    "                except Exception as e :\n",
    "                    self.logger.error(f\"Error while unfreezing layer {i + 1} ({layer.name}) : {e}\")\n",
    "            self.logger.info(f\"Unfroze last {N} layers\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def unfreeze_after_layer(self, layer_name : str = None) -> 'Model' :\n",
    "        try :\n",
    "            freeze = True\n",
    "            for i, layer in enumerate(self.model.layers) :\n",
    "                try :\n",
    "                    layer.trainable = not freeze\n",
    "                    if layer.name == layer_name :\n",
    "                        freeze = False\n",
    "                except Exception as e :\n",
    "                    self.logger.error(f\"Error during layer {i + 1} ({layer.name}) (freeze = {freeze}) : {e}\")\n",
    "            self.logger.info(f\"Unfroze layers after {layer_name}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def unfreeze_all(self) -> 'Model' :\n",
    "        try :\n",
    "            for i, layer in enumerate(self.model.layers) :\n",
    "                try :\n",
    "                    layer.trainable = True\n",
    "                except Exception as e :\n",
    "                    self.logger.error(f\"Error during layer {i + 1} ({layer.name}) : {e}\")\n",
    "            self.logger.info(\"All layers unfrozen\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    # ----------------- Add Layers ----------------- #\n",
    "    def _add_custom_layers_after_a_layer(self, output : tf.Tensor, layers : list[keras.layers.Layer]) -> tf.Tensor :\n",
    "        \"\"\"\n",
    "        Takes an output tensor from an existing layer and applies new layers on top.\n",
    "        \"\"\"\n",
    "        x = output\n",
    "        for l in layers :\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def add_custom_layers(self, layers_list : list[keras.layers.Layer] = None) -> 'Model' :\n",
    "        \"\"\"\n",
    "        layers_list : list of keras.layers.Layer\n",
    "                    If given, then adds these layer after layer_name\n",
    "                    If not given, adds custom layers from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if layers_list is None :\n",
    "                layers_list = get_custom_layers(self.config[\"num_classes\"])\n",
    "\n",
    "            self.outputs_layer = self._add_custom_layers_after_a_layer(self.outputs_layer, layers_list)\n",
    "\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(\"Added custom layers at the end\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def add_layers_in_between(self, layer_name : str, layers : list[keras.layers.Layer]) -> 'Model' :\n",
    "        \"\"\"\n",
    "        layers : list of keras.layers.Layer\n",
    "                    If given, then adds these layer after layer_name\n",
    "                    If not given, adds custom layers from config\n",
    "                    after adding these, adds the remaining layers from the model\n",
    "        \"\"\"\n",
    "        try :\n",
    "            target_layer = self.model.get_layer(layer_name)\n",
    "            index = self.model.layers.index(target_layer)\n",
    "\n",
    "            x = self._add_custom_layers_after_a_layer(target_layer.output, layers)\n",
    "\n",
    "            for layer in self.model.layers[index + 1 :] :\n",
    "                x = layer(x)\n",
    "\n",
    "            self.outputs_layer = x\n",
    "\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(f\"Added custom layers after {layer_name}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    # ----------------- Cut Layers ----------------- #\n",
    "    def cut_at_layer(self, layer_name : str) -> 'Model' :\n",
    "        try :\n",
    "            self.outputs_layer = self.model.get_layer(layer_name).output\n",
    "\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(f\"Cut model at {layer_name}\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def cut_at_layer_and_add_custom_layers(self, layer_name : str, layers_list : list[keras.layers.Layer] = None) -> 'Model' :\n",
    "        \"\"\"\n",
    "        layers_list : list of keras.layers.Layer\n",
    "                    If given, then adds these layer after layer_name\n",
    "                    If not given, adds custom layers from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if layers_list is None :\n",
    "                layers_list = get_custom_layers(self.config[\"num_classes\"])\n",
    "\n",
    "            outputs = self.model.get_layer(layer_name).output\n",
    "\n",
    "            self.outputs_layer = self._add_custom_layers_after_a_layer(outputs, layers_list)\n",
    "\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(f\"Cut model at {layer_name} and added custom layers\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    # ----------------- Remove Layers ----------------- #\n",
    "    def remove_last_layer(self) -> 'Model' :\n",
    "        try :\n",
    "            last_second_layer = self.model.layers[-2]\n",
    "            self.outputs_layer = last_second_layer.output\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(\"Removed last layer\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def remove_N_layers(self, N : int = None) -> 'Model' :\n",
    "        \"\"\"\n",
    "        If you do not provide N, it takes default from config\n",
    "        \"\"\"\n",
    "        try :\n",
    "            if N is None :\n",
    "                N = self.config[\"remove_N\"]\n",
    "            self.cut_at_layer(self.model.layers[-(N + 1)].name)\n",
    "            self.logger.info(f\"Removed last {N} layers\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self\n",
    "\n",
    "    def remove_layer_in_between(self, layer_name : str) -> 'Model' :\n",
    "        try :\n",
    "            target_layer = self.model.get_layer(layer_name)\n",
    "            index = self.model.layers.index(target_layer)\n",
    "            prev_layer = self.model.layers[index - 1]\n",
    "            self.outputs_layer = self._add_custom_layers_after_a_layer(prev_layer.output, self.model.layers[index + 1 :])\n",
    "            self.rebuild_model()\n",
    "            self.logger.info(f\"Removed {layer_name} layer and reconnected network\")\n",
    "        except Exception as e :\n",
    "            self.logger.error(e)\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
